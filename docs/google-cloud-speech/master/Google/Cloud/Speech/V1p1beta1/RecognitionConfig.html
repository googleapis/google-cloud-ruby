---
layout: yard_main
title: "Class: Google::Cloud::Speech::V1p1beta1::RecognitionConfig - Google"
css: 
  - /docs/css/style.css
  - /docs/css/common.css
  - /css/docs.css
js: 
  - /docs/js/app.js
  - /js/docs.js
---
<script type="text/javascript" charset="utf-8">
  pathId = "Google::Cloud::Speech::V1p1beta1::RecognitionConfig";
  relpath = '../../../../';
</script>


<div class="nav_wrap">
  <iframe id="nav" src="../../../../class_list.html?1"></iframe>
  <div id="resizer"></div>
</div>

<div id="main" tabindex="-1">
  <div id="header">
    <div id="menu">
  
    <a href="../../../../_index.html">Index (R)</a> &raquo;
    <span class='title'><span class='object_link'><a href="../../../../Google.html" title="Google (module)">Google</a></span></span> &raquo; <span class='title'><span class='object_link'><a href="../../../Cloud.html" title="Google::Cloud (module)">Cloud</a></span></span> &raquo; <span class='title'><span class='object_link'><a href="../../Speech.html" title="Google::Cloud::Speech (module)">Speech</a></span></span> &raquo; <span class='title'><span class='object_link'><a href="../V1p1beta1.html" title="Google::Cloud::Speech::V1p1beta1 (module)">V1p1beta1</a></span></span>
     &raquo; 
    <span class="title">RecognitionConfig</span>
  
</div>

    <div id="search">
  
    <a class="full_list_link" id="class_list_link"
        href="../../../../class_list.html">

        <svg width="24" height="24">
          <rect x="0" y="4" width="24" height="4" rx="1" ry="1"></rect>
          <rect x="0" y="12" width="24" height="4" rx="1" ry="1"></rect>
          <rect x="0" y="20" width="24" height="4" rx="1" ry="1"></rect>
        </svg>
    </a>
  
</div>
    <div class="clear"></div>
  </div>

  <div id="content"><h1>Class: Google::Cloud::Speech::V1p1beta1::RecognitionConfig
  
  
  
</h1>
<div class="box_info">
  
  <dl>
    <dt>Inherits:</dt>
    <dd>
      <span class="inheritName">Object</span>
      
        <ul class="fullTree">
          <li>Object</li>
          
            <li class="next">Google::Cloud::Speech::V1p1beta1::RecognitionConfig</li>
          
        </ul>
        <a href="#" class="inheritanceTree">show all</a>
      
    </dd>
  </dl>
  

  
  
  
  
  

  

  
  <dl>
    <dt>Defined in:</dt>
    <dd>lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb</dd>
  </dl>
  
</div>

<h2>Overview</h2><div class="docstring">
  <div class="discussion">
    <p>Provides information to the recognizer that specifies how to process the
request.</p>


  </div>
</div>
<div class="tags">
  

</div><h2>Defined Under Namespace</h2>
<p class="children">
  
    
      <strong class="modules">Modules:</strong> <span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span>
    
  
    
  
</p>




  <h2>Instance Attribute Summary <small><a href="#" class="summary_toggle">collapse</a></small></h2>
  <ul class="summary">
    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#alternative_language_codes-instance_method" title="#alternative_language_codes (instance method)">#<strong>alternative_language_codes</strong>  &#x21d2; Array&lt;String&gt; </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> A list of up to 3 additional <a href="https://www.rfc-editor.org/rfc/bcp/bcp47.txt">BCP-47</a> language tags, listing possible alternative languages of the supplied audio.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#audio_channel_count-instance_method" title="#audio_channel_count (instance method)">#<strong>audio_channel_count</strong>  &#x21d2; Integer </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> The number of channels in the input audio data.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#diarization_speaker_count-instance_method" title="#diarization_speaker_count (instance method)">#<strong>diarization_speaker_count</strong>  &#x21d2; Integer </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> If set, specifies the estimated number of speakers in the conversation.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#enable_automatic_punctuation-instance_method" title="#enable_automatic_punctuation (instance method)">#<strong>enable_automatic_punctuation</strong>  &#x21d2; true, false </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> If &#39;true&#39;, adds punctuation to recognition result hypotheses.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#enable_separate_recognition_per_channel-instance_method" title="#enable_separate_recognition_per_channel (instance method)">#<strong>enable_separate_recognition_per_channel</strong>  &#x21d2; true, false </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p>This needs to be set to ‘true’ explicitly and audio_channel_count &gt; 1 to get each channel recognized separately.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#enable_speaker_diarization-instance_method" title="#enable_speaker_diarization (instance method)">#<strong>enable_speaker_diarization</strong>  &#x21d2; true, false </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> If &#39;true&#39;, enables speaker detection for each recognized word in the top alternative of the recognition result using a speaker_tag provided in the WordInfo.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#enable_word_confidence-instance_method" title="#enable_word_confidence (instance method)">#<strong>enable_word_confidence</strong>  &#x21d2; true, false </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> If +true+, the top result includes a list of words and the confidence for those words.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#enable_word_time_offsets-instance_method" title="#enable_word_time_offsets (instance method)">#<strong>enable_word_time_offsets</strong>  &#x21d2; true, false </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> If +true+, the top result includes a list of words and the start and end time offsets (timestamps) for those words.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#encoding-instance_method" title="#encoding (instance method)">#<strong>encoding</strong>  &#x21d2; Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p>Encoding of audio data sent in all +RecognitionAudio+ messages.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#language_code-instance_method" title="#language_code (instance method)">#<strong>language_code</strong>  &#x21d2; String </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Required</em> The language of the supplied audio as a <a href="https://www.rfc-editor.org/rfc/bcp/bcp47.txt">BCP-47</a> language tag.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#max_alternatives-instance_method" title="#max_alternatives (instance method)">#<strong>max_alternatives</strong>  &#x21d2; Integer </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> Maximum number of recognition hypotheses to be returned.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#metadata-instance_method" title="#metadata (instance method)">#<strong>metadata</strong>  &#x21d2; Google::Cloud::Speech::V1p1beta1::RecognitionMetadata </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> Metadata regarding this request.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#model-instance_method" title="#model (instance method)">#<strong>model</strong>  &#x21d2; String </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> Which model to select for the given request.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#profanity_filter-instance_method" title="#profanity_filter (instance method)">#<strong>profanity_filter</strong>  &#x21d2; true, false </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> If set to +true+, the server will attempt to filter out profanities, replacing all but the initial character in each filtered word with asterisks, e.g.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#sample_rate_hertz-instance_method" title="#sample_rate_hertz (instance method)">#<strong>sample_rate_hertz</strong>  &#x21d2; Integer </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p>Sample rate in Hertz of the audio data sent in all +RecognitionAudio+ messages.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#speech_contexts-instance_method" title="#speech_contexts (instance method)">#<strong>speech_contexts</strong>  &#x21d2; Array&lt;Google::Cloud::Speech::V1p1beta1::SpeechContext&gt; </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> A means to provide context to assist the speech recognition.</p>
</div></span>
  
</li>

    
      <li class="public ">
  <span class="summary_signature">
    
      <a href="#use_enhanced-instance_method" title="#use_enhanced (instance method)">#<strong>use_enhanced</strong>  &#x21d2; true, false </a>
    

    
  </span>
  
  
  
    
    
  
  
  
  
  

  
    <span class="summary_desc"><div class='inline'><p><em>Optional</em> Set to true to use an enhanced model for speech recognition.</p>
</div></span>
  
</li>

    
  </ul>





  <div id="instance_attr_details" class="attr_details">
    <h2>Instance Attribute Details</h2>
    
      
      <span id="alternative_language_codes=-instance_method"></span>
      <div class="method_details first">
  <h3 class="signature first" id="alternative_language_codes-instance_method">
  
    #<strong>alternative_language_codes</strong>  &#x21d2; <tt>Array&lt;String&gt;</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> A list of up to 3 additional
<a href="https://www.rfc-editor.org/rfc/bcp/bcp47.txt">BCP-47</a> language tags,
listing possible alternative languages of the supplied audio.
See <a href="https://cloud.google.com/speech/docs/languages">Language Support</a>
for a list of the currently supported language codes.
If alternative languages are listed, recognition result will contain
recognition in the most likely language detected including the main
language_code. The recognition result will include the language tag
of the language detected in the audio.
NOTE: This feature is only supported for Voice Command and Voice Search
use cases and performance may vary for other use cases (e.g., phone call
transcription).</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>Array&lt;String&gt;</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> A list of up to 3 additional
<a href="https://www.rfc-editor.org/rfc/bcp/bcp47.txt">BCP-47</a> language tags,
listing possible alternative languages of the supplied audio.
See <a href="https://cloud.google.com/speech/docs/languages">Language Support</a>
for a list of the currently supported language codes.
If alternative languages are listed, recognition result will contain
recognition in the most likely language detected including the main
language_code. The recognition result will include the language tag
of the language detected in the audio.
NOTE: This feature is only supported for Voice Command and Voice Search
use cases and performance may vary for other use cases (e.g., phone call
transcription).</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb', line 258</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (+FLAC+ or +LINEAR16+). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># +MULAW+, +AMR+, +AMR_WB+, +OGG_OPUS+, and +SPEEX_WITH_HEADER_BYTE+.
</span>  <span class='comment'>#
</span>  <span class='comment'># The +FLAC+ and +WAV+ audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for +WAV+ files that
</span>  <span class='comment'># contain either +LINEAR16+ or +MULAW+ encoded audio.
</span>  <span class='comment'># If you send +FLAC+ or +WAV+ audio file format in
</span>  <span class='comment'># your request, you do not need to specify an +AudioEncoding+; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an +AudioEncoding+ when you send  send +FLAC+ or +WAV+ audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># +FLAC+ (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of +LINEAR16+. +FLAC+ stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># +STREAMINFO+ are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. +sample_rate_hertz+ must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># +sample_rate_hertz+ must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, +OGG_OPUS+ is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># +audio/x-speex-with-header-byte+.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="audio_channel_count=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="audio_channel_count-instance_method">
  
    #<strong>audio_channel_count</strong>  &#x21d2; <tt>Integer</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> The number of channels in the input audio data.
ONLY set this for MULTI-CHANNEL recognition.
Valid values for LINEAR16 and FLAC are +1+-+8+.
Valid values for OGG_OPUS are &#39;1&#39;-&#39;254&#39;.
Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only +1+.
If +0+ or omitted, defaults to one channel (mono).
NOTE: We only recognize the first channel by default.
To perform independent recognition on each channel set
enable_separate_recognition_per_channel to &#39;true&#39;.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>Integer</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> The number of channels in the input audio data.
ONLY set this for MULTI-CHANNEL recognition.
Valid values for LINEAR16 and FLAC are +1+-+8+.
Valid values for OGG_OPUS are &#39;1&#39;-&#39;254&#39;.
Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only +1+.
If +0+ or omitted, defaults to one channel (mono).
NOTE: We only recognize the first channel by default.
To perform independent recognition on each channel set
enable_separate_recognition_per_channel to &#39;true&#39;.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb', line 258</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (+FLAC+ or +LINEAR16+). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># +MULAW+, +AMR+, +AMR_WB+, +OGG_OPUS+, and +SPEEX_WITH_HEADER_BYTE+.
</span>  <span class='comment'>#
</span>  <span class='comment'># The +FLAC+ and +WAV+ audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for +WAV+ files that
</span>  <span class='comment'># contain either +LINEAR16+ or +MULAW+ encoded audio.
</span>  <span class='comment'># If you send +FLAC+ or +WAV+ audio file format in
</span>  <span class='comment'># your request, you do not need to specify an +AudioEncoding+; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an +AudioEncoding+ when you send  send +FLAC+ or +WAV+ audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># +FLAC+ (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of +LINEAR16+. +FLAC+ stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># +STREAMINFO+ are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. +sample_rate_hertz+ must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># +sample_rate_hertz+ must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, +OGG_OPUS+ is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># +audio/x-speex-with-header-byte+.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="diarization_speaker_count=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="diarization_speaker_count-instance_method">
  
    #<strong>diarization_speaker_count</strong>  &#x21d2; <tt>Integer</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em>
If set, specifies the estimated number of speakers in the conversation.
If not set, defaults to &#39;2&#39;.
Ignored unless enable_speaker_diarization is set to true.&quot;</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>Integer</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em>
If set, specifies the estimated number of speakers in the conversation.
If not set, defaults to &#39;2&#39;.
Ignored unless enable_speaker_diarization is set to true.&quot;</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb', line 258</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (+FLAC+ or +LINEAR16+). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># +MULAW+, +AMR+, +AMR_WB+, +OGG_OPUS+, and +SPEEX_WITH_HEADER_BYTE+.
</span>  <span class='comment'>#
</span>  <span class='comment'># The +FLAC+ and +WAV+ audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for +WAV+ files that
</span>  <span class='comment'># contain either +LINEAR16+ or +MULAW+ encoded audio.
</span>  <span class='comment'># If you send +FLAC+ or +WAV+ audio file format in
</span>  <span class='comment'># your request, you do not need to specify an +AudioEncoding+; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an +AudioEncoding+ when you send  send +FLAC+ or +WAV+ audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># +FLAC+ (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of +LINEAR16+. +FLAC+ stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># +STREAMINFO+ are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. +sample_rate_hertz+ must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># +sample_rate_hertz+ must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, +OGG_OPUS+ is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># +audio/x-speex-with-header-byte+.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="enable_automatic_punctuation=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="enable_automatic_punctuation-instance_method">
  
    #<strong>enable_automatic_punctuation</strong>  &#x21d2; <tt>true</tt>, <tt>false</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> If &#39;true&#39;, adds punctuation to recognition result hypotheses.
This feature is only available in select languages. Setting this for
requests in other languages has no effect at all.
The default &#39;false&#39; value does not add punctuation to result hypotheses.
NOTE: &quot;This is currently offered as an experimental service, complimentary
to all users. In the future this may be exclusively available as a
premium feature.&quot;</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>true</tt>, <tt>false</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> If &#39;true&#39;, adds punctuation to recognition result hypotheses.
This feature is only available in select languages. Setting this for
requests in other languages has no effect at all.
The default &#39;false&#39; value does not add punctuation to result hypotheses.
NOTE: &quot;This is currently offered as an experimental service, complimentary
to all users. In the future this may be exclusively available as a
premium feature.&quot;</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb', line 258</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (+FLAC+ or +LINEAR16+). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># +MULAW+, +AMR+, +AMR_WB+, +OGG_OPUS+, and +SPEEX_WITH_HEADER_BYTE+.
</span>  <span class='comment'>#
</span>  <span class='comment'># The +FLAC+ and +WAV+ audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for +WAV+ files that
</span>  <span class='comment'># contain either +LINEAR16+ or +MULAW+ encoded audio.
</span>  <span class='comment'># If you send +FLAC+ or +WAV+ audio file format in
</span>  <span class='comment'># your request, you do not need to specify an +AudioEncoding+; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an +AudioEncoding+ when you send  send +FLAC+ or +WAV+ audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># +FLAC+ (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of +LINEAR16+. +FLAC+ stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># +STREAMINFO+ are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. +sample_rate_hertz+ must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># +sample_rate_hertz+ must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, +OGG_OPUS+ is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># +audio/x-speex-with-header-byte+.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="enable_separate_recognition_per_channel=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="enable_separate_recognition_per_channel-instance_method">
  
    #<strong>enable_separate_recognition_per_channel</strong>  &#x21d2; <tt>true</tt>, <tt>false</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns This needs to be set to ‘true’ explicitly and audio_channel_count &gt; 1
to get each channel recognized separately. The recognition result will
contain a channel_tag field to state which channel that result belongs to.
If this is not ‘true’, we will only recognize the first channel.
NOTE: The request is also billed cumulatively for all channels recognized:
    (audio_channel_count times the audio length)</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>true</tt>, <tt>false</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p>This needs to be set to ‘true’ explicitly and audio_channel_count &gt; 1
to get each channel recognized separately. The recognition result will
contain a channel_tag field to state which channel that result belongs to.
If this is not ‘true’, we will only recognize the first channel.
NOTE: The request is also billed cumulatively for all channels recognized:
    (audio_channel_count times the audio length)</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb', line 258</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (+FLAC+ or +LINEAR16+). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># +MULAW+, +AMR+, +AMR_WB+, +OGG_OPUS+, and +SPEEX_WITH_HEADER_BYTE+.
</span>  <span class='comment'>#
</span>  <span class='comment'># The +FLAC+ and +WAV+ audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for +WAV+ files that
</span>  <span class='comment'># contain either +LINEAR16+ or +MULAW+ encoded audio.
</span>  <span class='comment'># If you send +FLAC+ or +WAV+ audio file format in
</span>  <span class='comment'># your request, you do not need to specify an +AudioEncoding+; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an +AudioEncoding+ when you send  send +FLAC+ or +WAV+ audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># +FLAC+ (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of +LINEAR16+. +FLAC+ stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># +STREAMINFO+ are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. +sample_rate_hertz+ must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># +sample_rate_hertz+ must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, +OGG_OPUS+ is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># +audio/x-speex-with-header-byte+.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="enable_speaker_diarization=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="enable_speaker_diarization-instance_method">
  
    #<strong>enable_speaker_diarization</strong>  &#x21d2; <tt>true</tt>, <tt>false</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> If &#39;true&#39;, enables speaker detection for each recognized word in
the top alternative of the recognition result using a speaker_tag provided
in the WordInfo.
Note: When this is true, we send all the words from the beginning of the
audio for the top alternative in every consecutive responses.
This is done in order to improve our speaker tags as our models learn to
identify the speakers in the conversation over time.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>true</tt>, <tt>false</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> If &#39;true&#39;, enables speaker detection for each recognized word in
the top alternative of the recognition result using a speaker_tag provided
in the WordInfo.
Note: When this is true, we send all the words from the beginning of the
audio for the top alternative in every consecutive responses.
This is done in order to improve our speaker tags as our models learn to
identify the speakers in the conversation over time.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb', line 258</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (+FLAC+ or +LINEAR16+). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># +MULAW+, +AMR+, +AMR_WB+, +OGG_OPUS+, and +SPEEX_WITH_HEADER_BYTE+.
</span>  <span class='comment'>#
</span>  <span class='comment'># The +FLAC+ and +WAV+ audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for +WAV+ files that
</span>  <span class='comment'># contain either +LINEAR16+ or +MULAW+ encoded audio.
</span>  <span class='comment'># If you send +FLAC+ or +WAV+ audio file format in
</span>  <span class='comment'># your request, you do not need to specify an +AudioEncoding+; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an +AudioEncoding+ when you send  send +FLAC+ or +WAV+ audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># +FLAC+ (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of +LINEAR16+. +FLAC+ stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># +STREAMINFO+ are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. +sample_rate_hertz+ must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># +sample_rate_hertz+ must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, +OGG_OPUS+ is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># +audio/x-speex-with-header-byte+.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="enable_word_confidence=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="enable_word_confidence-instance_method">
  
    #<strong>enable_word_confidence</strong>  &#x21d2; <tt>true</tt>, <tt>false</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> If +true+, the top result includes a list of words and the
confidence for those words. If +false+, no word-level confidence
information is returned. The default is +false+.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>true</tt>, <tt>false</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> If +true+, the top result includes a list of words and the
confidence for those words. If +false+, no word-level confidence
information is returned. The default is +false+.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb', line 258</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (+FLAC+ or +LINEAR16+). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># +MULAW+, +AMR+, +AMR_WB+, +OGG_OPUS+, and +SPEEX_WITH_HEADER_BYTE+.
</span>  <span class='comment'>#
</span>  <span class='comment'># The +FLAC+ and +WAV+ audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for +WAV+ files that
</span>  <span class='comment'># contain either +LINEAR16+ or +MULAW+ encoded audio.
</span>  <span class='comment'># If you send +FLAC+ or +WAV+ audio file format in
</span>  <span class='comment'># your request, you do not need to specify an +AudioEncoding+; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an +AudioEncoding+ when you send  send +FLAC+ or +WAV+ audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># +FLAC+ (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of +LINEAR16+. +FLAC+ stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># +STREAMINFO+ are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. +sample_rate_hertz+ must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># +sample_rate_hertz+ must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, +OGG_OPUS+ is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># +audio/x-speex-with-header-byte+.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="enable_word_time_offsets=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="enable_word_time_offsets-instance_method">
  
    #<strong>enable_word_time_offsets</strong>  &#x21d2; <tt>true</tt>, <tt>false</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> If +true+, the top result includes a list of words and
the start and end time offsets (timestamps) for those words. If
+false+, no word-level time offset information is returned. The default is
+false+.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>true</tt>, <tt>false</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> If +true+, the top result includes a list of words and
the start and end time offsets (timestamps) for those words. If
+false+, no word-level time offset information is returned. The default is
+false+.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb', line 258</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (+FLAC+ or +LINEAR16+). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># +MULAW+, +AMR+, +AMR_WB+, +OGG_OPUS+, and +SPEEX_WITH_HEADER_BYTE+.
</span>  <span class='comment'>#
</span>  <span class='comment'># The +FLAC+ and +WAV+ audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for +WAV+ files that
</span>  <span class='comment'># contain either +LINEAR16+ or +MULAW+ encoded audio.
</span>  <span class='comment'># If you send +FLAC+ or +WAV+ audio file format in
</span>  <span class='comment'># your request, you do not need to specify an +AudioEncoding+; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an +AudioEncoding+ when you send  send +FLAC+ or +WAV+ audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># +FLAC+ (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of +LINEAR16+. +FLAC+ stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># +STREAMINFO+ are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. +sample_rate_hertz+ must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># +sample_rate_hertz+ must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, +OGG_OPUS+ is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># +audio/x-speex-with-header-byte+.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="encoding=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="encoding-instance_method">
  
    #<strong>encoding</strong>  &#x21d2; <tt><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding</a></span></tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns Encoding of audio data sent in all +RecognitionAudio+ messages.
This field is optional for +FLAC+ and +WAV+ audio files and required
for all other audio formats. For details, see <span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span>.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding</a></span></tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p>Encoding of audio data sent in all +RecognitionAudio+ messages.
This field is optional for +FLAC+ and +WAV+ audio files and required
for all other audio formats. For details, see <span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span>.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb', line 258</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (+FLAC+ or +LINEAR16+). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># +MULAW+, +AMR+, +AMR_WB+, +OGG_OPUS+, and +SPEEX_WITH_HEADER_BYTE+.
</span>  <span class='comment'>#
</span>  <span class='comment'># The +FLAC+ and +WAV+ audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for +WAV+ files that
</span>  <span class='comment'># contain either +LINEAR16+ or +MULAW+ encoded audio.
</span>  <span class='comment'># If you send +FLAC+ or +WAV+ audio file format in
</span>  <span class='comment'># your request, you do not need to specify an +AudioEncoding+; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an +AudioEncoding+ when you send  send +FLAC+ or +WAV+ audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># +FLAC+ (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of +LINEAR16+. +FLAC+ stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># +STREAMINFO+ are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. +sample_rate_hertz+ must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># +sample_rate_hertz+ must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, +OGG_OPUS+ is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># +audio/x-speex-with-header-byte+.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="language_code=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="language_code-instance_method">
  
    #<strong>language_code</strong>  &#x21d2; <tt>String</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Required</em> The language of the supplied audio as a
<a href="https://www.rfc-editor.org/rfc/bcp/bcp47.txt">BCP-47</a> language tag.
Example: &quot;en-US&quot;.
See <a href="https://cloud.google.com/speech/docs/languages">Language Support</a>
for a list of the currently supported language codes.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>String</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Required</em> The language of the supplied audio as a
<a href="https://www.rfc-editor.org/rfc/bcp/bcp47.txt">BCP-47</a> language tag.
Example: &quot;en-US&quot;.
See <a href="https://cloud.google.com/speech/docs/languages">Language Support</a>
for a list of the currently supported language codes.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb', line 258</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (+FLAC+ or +LINEAR16+). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># +MULAW+, +AMR+, +AMR_WB+, +OGG_OPUS+, and +SPEEX_WITH_HEADER_BYTE+.
</span>  <span class='comment'>#
</span>  <span class='comment'># The +FLAC+ and +WAV+ audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for +WAV+ files that
</span>  <span class='comment'># contain either +LINEAR16+ or +MULAW+ encoded audio.
</span>  <span class='comment'># If you send +FLAC+ or +WAV+ audio file format in
</span>  <span class='comment'># your request, you do not need to specify an +AudioEncoding+; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an +AudioEncoding+ when you send  send +FLAC+ or +WAV+ audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># +FLAC+ (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of +LINEAR16+. +FLAC+ stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># +STREAMINFO+ are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. +sample_rate_hertz+ must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># +sample_rate_hertz+ must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, +OGG_OPUS+ is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># +audio/x-speex-with-header-byte+.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="max_alternatives=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="max_alternatives-instance_method">
  
    #<strong>max_alternatives</strong>  &#x21d2; <tt>Integer</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> Maximum number of recognition hypotheses to be returned.
Specifically, the maximum number of +SpeechRecognitionAlternative+ messages
within each +SpeechRecognitionResult+.
The server may return fewer than +max_alternatives+.
Valid values are +0+-+30+. A value of +0+ or +1+ will return a maximum of
one. If omitted, will return a maximum of one.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>Integer</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> Maximum number of recognition hypotheses to be returned.
Specifically, the maximum number of +SpeechRecognitionAlternative+ messages
within each +SpeechRecognitionResult+.
The server may return fewer than +max_alternatives+.
Valid values are +0+-+30+. A value of +0+ or +1+ will return a maximum of
one. If omitted, will return a maximum of one.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb', line 258</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (+FLAC+ or +LINEAR16+). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># +MULAW+, +AMR+, +AMR_WB+, +OGG_OPUS+, and +SPEEX_WITH_HEADER_BYTE+.
</span>  <span class='comment'>#
</span>  <span class='comment'># The +FLAC+ and +WAV+ audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for +WAV+ files that
</span>  <span class='comment'># contain either +LINEAR16+ or +MULAW+ encoded audio.
</span>  <span class='comment'># If you send +FLAC+ or +WAV+ audio file format in
</span>  <span class='comment'># your request, you do not need to specify an +AudioEncoding+; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an +AudioEncoding+ when you send  send +FLAC+ or +WAV+ audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># +FLAC+ (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of +LINEAR16+. +FLAC+ stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># +STREAMINFO+ are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. +sample_rate_hertz+ must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># +sample_rate_hertz+ must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, +OGG_OPUS+ is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># +audio/x-speex-with-header-byte+.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="metadata=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="metadata-instance_method">
  
    #<strong>metadata</strong>  &#x21d2; <tt><span class='object_link'><a href="RecognitionMetadata.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionMetadata (class)">Google::Cloud::Speech::V1p1beta1::RecognitionMetadata</a></span></tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> Metadata regarding this request.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt><span class='object_link'><a href="RecognitionMetadata.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionMetadata (class)">Google::Cloud::Speech::V1p1beta1::RecognitionMetadata</a></span></tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> Metadata regarding this request.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb', line 258</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (+FLAC+ or +LINEAR16+). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># +MULAW+, +AMR+, +AMR_WB+, +OGG_OPUS+, and +SPEEX_WITH_HEADER_BYTE+.
</span>  <span class='comment'>#
</span>  <span class='comment'># The +FLAC+ and +WAV+ audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for +WAV+ files that
</span>  <span class='comment'># contain either +LINEAR16+ or +MULAW+ encoded audio.
</span>  <span class='comment'># If you send +FLAC+ or +WAV+ audio file format in
</span>  <span class='comment'># your request, you do not need to specify an +AudioEncoding+; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an +AudioEncoding+ when you send  send +FLAC+ or +WAV+ audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># +FLAC+ (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of +LINEAR16+. +FLAC+ stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># +STREAMINFO+ are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. +sample_rate_hertz+ must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># +sample_rate_hertz+ must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, +OGG_OPUS+ is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># +audio/x-speex-with-header-byte+.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="model=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="model-instance_method">
  
    #<strong>model</strong>  &#x21d2; <tt>String</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> Which model to select for the given request. Select the model
best suited to your domain to get best results. If a model is not
explicitly specified, then we auto-select a model based on the parameters
in the RecognitionConfig.</p>

<table>
  <tr>
    <td><b>Model</b></td>
    <td><b>Description</b></td>
  </tr>
  <tr>
    <td><code>command_and_search</code></td>
    <td>Best for short queries such as voice commands or voice search.</td>
  </tr>
  <tr>
    <td><code>phone_call</code></td>
    <td>Best for audio that originated from a phone call (typically
    recorded at an 8khz sampling rate).</td>
  </tr>
  <tr>
    <td><code>video</code></td>
    <td>Best for audio that originated from from video or includes multiple
        speakers. Ideally the audio is recorded at a 16khz or greater
        sampling rate. This is a premium model that costs more than the
        standard rate.</td>
  </tr>
  <tr>
    <td><code>default</code></td>
    <td>Best for audio that is not one of the specific audio models.
        For example, long-form audio. Ideally the audio is high-fidelity,
        recorded at a 16khz or greater sampling rate.</td>
  </tr>
</table>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>String</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> Which model to select for the given request. Select the model
best suited to your domain to get best results. If a model is not
explicitly specified, then we auto-select a model based on the parameters
in the RecognitionConfig.</p>

<table>
  <tr>
    <td><b>Model</b></td>
    <td><b>Description</b></td>
  </tr>
  <tr>
    <td><code>command_and_search</code></td>
    <td>Best for short queries such as voice commands or voice search.</td>
  </tr>
  <tr>
    <td><code>phone_call</code></td>
    <td>Best for audio that originated from a phone call (typically
    recorded at an 8khz sampling rate).</td>
  </tr>
  <tr>
    <td><code>video</code></td>
    <td>Best for audio that originated from from video or includes multiple
        speakers. Ideally the audio is recorded at a 16khz or greater
        sampling rate. This is a premium model that costs more than the
        standard rate.</td>
  </tr>
  <tr>
    <td><code>default</code></td>
    <td>Best for audio that is not one of the specific audio models.
        For example, long-form audio. Ideally the audio is high-fidelity,
        recorded at a 16khz or greater sampling rate.</td>
  </tr>
</table>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb', line 258</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (+FLAC+ or +LINEAR16+). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># +MULAW+, +AMR+, +AMR_WB+, +OGG_OPUS+, and +SPEEX_WITH_HEADER_BYTE+.
</span>  <span class='comment'>#
</span>  <span class='comment'># The +FLAC+ and +WAV+ audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for +WAV+ files that
</span>  <span class='comment'># contain either +LINEAR16+ or +MULAW+ encoded audio.
</span>  <span class='comment'># If you send +FLAC+ or +WAV+ audio file format in
</span>  <span class='comment'># your request, you do not need to specify an +AudioEncoding+; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an +AudioEncoding+ when you send  send +FLAC+ or +WAV+ audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># +FLAC+ (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of +LINEAR16+. +FLAC+ stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># +STREAMINFO+ are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. +sample_rate_hertz+ must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># +sample_rate_hertz+ must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, +OGG_OPUS+ is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># +audio/x-speex-with-header-byte+.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="profanity_filter=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="profanity_filter-instance_method">
  
    #<strong>profanity_filter</strong>  &#x21d2; <tt>true</tt>, <tt>false</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> If set to +true+, the server will attempt to filter out
profanities, replacing all but the initial character in each filtered word
with asterisks, e.g. &quot;f***&quot;. If set to +false+ or omitted, profanities
won&#39;t be filtered out.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>true</tt>, <tt>false</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> If set to +true+, the server will attempt to filter out
profanities, replacing all but the initial character in each filtered word
with asterisks, e.g. &quot;f***&quot;. If set to +false+ or omitted, profanities
won&#39;t be filtered out.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb', line 258</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (+FLAC+ or +LINEAR16+). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># +MULAW+, +AMR+, +AMR_WB+, +OGG_OPUS+, and +SPEEX_WITH_HEADER_BYTE+.
</span>  <span class='comment'>#
</span>  <span class='comment'># The +FLAC+ and +WAV+ audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for +WAV+ files that
</span>  <span class='comment'># contain either +LINEAR16+ or +MULAW+ encoded audio.
</span>  <span class='comment'># If you send +FLAC+ or +WAV+ audio file format in
</span>  <span class='comment'># your request, you do not need to specify an +AudioEncoding+; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an +AudioEncoding+ when you send  send +FLAC+ or +WAV+ audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># +FLAC+ (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of +LINEAR16+. +FLAC+ stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># +STREAMINFO+ are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. +sample_rate_hertz+ must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># +sample_rate_hertz+ must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, +OGG_OPUS+ is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># +audio/x-speex-with-header-byte+.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="sample_rate_hertz=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="sample_rate_hertz-instance_method">
  
    #<strong>sample_rate_hertz</strong>  &#x21d2; <tt>Integer</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns Sample rate in Hertz of the audio data sent in all
+RecognitionAudio+ messages. Valid values are: 8000-48000.
16000 is optimal. For best results, set the sampling rate of the audio
source to 16000 Hz. If that&#39;s not possible, use the native sample rate of
the audio source (instead of re-sampling).
This field is optional for +FLAC+ and +WAV+ audio files and required
for all other audio formats. For details, see <span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span>.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>Integer</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p>Sample rate in Hertz of the audio data sent in all
+RecognitionAudio+ messages. Valid values are: 8000-48000.
16000 is optimal. For best results, set the sampling rate of the audio
source to 16000 Hz. If that&#39;s not possible, use the native sample rate of
the audio source (instead of re-sampling).
This field is optional for +FLAC+ and +WAV+ audio files and required
for all other audio formats. For details, see <span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span>.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb', line 258</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (+FLAC+ or +LINEAR16+). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># +MULAW+, +AMR+, +AMR_WB+, +OGG_OPUS+, and +SPEEX_WITH_HEADER_BYTE+.
</span>  <span class='comment'>#
</span>  <span class='comment'># The +FLAC+ and +WAV+ audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for +WAV+ files that
</span>  <span class='comment'># contain either +LINEAR16+ or +MULAW+ encoded audio.
</span>  <span class='comment'># If you send +FLAC+ or +WAV+ audio file format in
</span>  <span class='comment'># your request, you do not need to specify an +AudioEncoding+; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an +AudioEncoding+ when you send  send +FLAC+ or +WAV+ audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># +FLAC+ (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of +LINEAR16+. +FLAC+ stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># +STREAMINFO+ are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. +sample_rate_hertz+ must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># +sample_rate_hertz+ must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, +OGG_OPUS+ is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># +audio/x-speex-with-header-byte+.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="speech_contexts=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="speech_contexts-instance_method">
  
    #<strong>speech_contexts</strong>  &#x21d2; <tt>Array&lt;<span class='object_link'><a href="SpeechContext.html" title="Google::Cloud::Speech::V1p1beta1::SpeechContext (class)">Google::Cloud::Speech::V1p1beta1::SpeechContext</a></span>&gt;</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> A means to provide context to assist the speech recognition.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>Array&lt;<span class='object_link'><a href="SpeechContext.html" title="Google::Cloud::Speech::V1p1beta1::SpeechContext (class)">Google::Cloud::Speech::V1p1beta1::SpeechContext</a></span>&gt;</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> A means to provide context to assist the speech recognition.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb', line 258</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (+FLAC+ or +LINEAR16+). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># +MULAW+, +AMR+, +AMR_WB+, +OGG_OPUS+, and +SPEEX_WITH_HEADER_BYTE+.
</span>  <span class='comment'>#
</span>  <span class='comment'># The +FLAC+ and +WAV+ audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for +WAV+ files that
</span>  <span class='comment'># contain either +LINEAR16+ or +MULAW+ encoded audio.
</span>  <span class='comment'># If you send +FLAC+ or +WAV+ audio file format in
</span>  <span class='comment'># your request, you do not need to specify an +AudioEncoding+; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an +AudioEncoding+ when you send  send +FLAC+ or +WAV+ audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># +FLAC+ (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of +LINEAR16+. +FLAC+ stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># +STREAMINFO+ are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. +sample_rate_hertz+ must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># +sample_rate_hertz+ must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, +OGG_OPUS+ is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># +audio/x-speex-with-header-byte+.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
      
      <span id="use_enhanced=-instance_method"></span>
      <div class="method_details ">
  <h3 class="signature " id="use_enhanced-instance_method">
  
    #<strong>use_enhanced</strong>  &#x21d2; <tt>true</tt>, <tt>false</tt> 
  

  

  
</h3><div class="docstring">
  <div class="discussion">
    <p>Returns <em>Optional</em> Set to true to use an enhanced model for speech recognition.
You must also set the +model+ field to a valid, enhanced model. If
+use_enhanced+ is set to true and the +model+ field is not set, then
+use_enhanced+ is ignored. If +use_enhanced+ is true and an enhanced
version of the specified model does not exist, then the speech is
recognized using the standard version of the specified model.</p>

<p>Enhanced speech models require that you opt-in to the audio logging using
instructions in the <a href="https://cloud.google.com/speech/data-sharing">alpha documentation</a>. If you set
+use_enhanced+ to true and you have not enabled audio logging, then you
will receive an error.</p>


  </div>
</div>
<div class="tags">
  
<p class="tag_title">Returns:</p>
<ul class="return">
  
    <li>
      
      
        <span class='type'>(<tt>true</tt>, <tt>false</tt>)</span>
      
      
      
        &mdash;
        <div class='inline'><p><em>Optional</em> Set to true to use an enhanced model for speech recognition.
You must also set the +model+ field to a valid, enhanced model. If
+use_enhanced+ is set to true and the +model+ field is not set, then
+use_enhanced+ is ignored. If +use_enhanced+ is true and an enhanced
version of the specified model does not exist, then the speech is
recognized using the standard version of the specified model.</p>

<p>Enhanced speech models require that you opt-in to the audio logging using
instructions in the <a href="https://cloud.google.com/speech/data-sharing">alpha documentation</a>. If you set
+use_enhanced+ to true and you have not enabled audio logging, then you
will receive an error.</p>
</div>
      
    </li>
  
</ul>

</div><table class="source_code">
  <tr>
    <td>
      <pre class="lines">


258
259
260
261
262
263
264
265
266
267
268
269
270
271
272
273
274
275
276
277
278
279
280
281
282
283
284
285
286
287
288
289
290
291
292
293
294
295
296
297
298
299
300
301
302
303
304
305
306
307
308
309
310
311
312
313
314
315
316
317
318
319
320
321
322
323</pre>
    </td>
    <td>
      <pre class="code"><span class="info file"># File 'lib/google/cloud/speech/v1p1beta1/doc/google/cloud/speech/v1p1beta1/cloud_speech.rb', line 258</span>

<span class='kw'>class</span> <span class='const'><span class='object_link'><a href="" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig (class)">RecognitionConfig</a></span></span>
  <span class='comment'># The encoding of the audio data sent in the request.
</span>  <span class='comment'>#
</span>  <span class='comment'># All encodings support only 1 channel (mono) audio.
</span>  <span class='comment'>#
</span>  <span class='comment'># For best results, the audio source should be captured and transmitted using
</span>  <span class='comment'># a lossless encoding (+FLAC+ or +LINEAR16+). The accuracy of the speech
</span>  <span class='comment'># recognition can be reduced if lossy codecs are used to capture or transmit
</span>  <span class='comment'># audio, particularly if background noise is present. Lossy codecs include
</span>  <span class='comment'># +MULAW+, +AMR+, +AMR_WB+, +OGG_OPUS+, and +SPEEX_WITH_HEADER_BYTE+.
</span>  <span class='comment'>#
</span>  <span class='comment'># The +FLAC+ and +WAV+ audio file formats include a header that describes the
</span>  <span class='comment'># included audio content. You can request recognition for +WAV+ files that
</span>  <span class='comment'># contain either +LINEAR16+ or +MULAW+ encoded audio.
</span>  <span class='comment'># If you send +FLAC+ or +WAV+ audio file format in
</span>  <span class='comment'># your request, you do not need to specify an +AudioEncoding+; the audio
</span>  <span class='comment'># encoding format is determined from the file header. If you specify
</span>  <span class='comment'># an +AudioEncoding+ when you send  send +FLAC+ or +WAV+ audio, the
</span>  <span class='comment'># encoding configuration must match the encoding described in the audio
</span>  <span class='comment'># header; otherwise the request returns an
</span>  <span class='comment'># {Google::Rpc::Code::INVALID_ARGUMENT} error code.
</span>  <span class='kw'>module</span> <span class='const'><span class='object_link'><a href="RecognitionConfig/AudioEncoding.html" title="Google::Cloud::Speech::V1p1beta1::RecognitionConfig::AudioEncoding (module)">AudioEncoding</a></span></span>
    <span class='comment'># Not specified.
</span>    <span class='const'>ENCODING_UNSPECIFIED</span> <span class='op'>=</span> <span class='int'>0</span>

    <span class='comment'># Uncompressed 16-bit signed little-endian samples (Linear PCM).
</span>    <span class='const'>LINEAR16</span> <span class='op'>=</span> <span class='int'>1</span>

    <span class='comment'># +FLAC+ (Free Lossless Audio
</span>    <span class='comment'># Codec) is the recommended encoding because it is
</span>    <span class='comment'># lossless--therefore recognition is not compromised--and
</span>    <span class='comment'># requires only about half the bandwidth of +LINEAR16+. +FLAC+ stream
</span>    <span class='comment'># encoding supports 16-bit and 24-bit samples, however, not all fields in
</span>    <span class='comment'># +STREAMINFO+ are supported.
</span>    <span class='const'>FLAC</span> <span class='op'>=</span> <span class='int'>2</span>

    <span class='comment'># 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
</span>    <span class='const'>MULAW</span> <span class='op'>=</span> <span class='int'>3</span>

    <span class='comment'># Adaptive Multi-Rate Narrowband codec. +sample_rate_hertz+ must be 8000.
</span>    <span class='const'>AMR</span> <span class='op'>=</span> <span class='int'>4</span>

    <span class='comment'># Adaptive Multi-Rate Wideband codec. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>AMR_WB</span> <span class='op'>=</span> <span class='int'>5</span>

    <span class='comment'># Opus encoded audio frames in Ogg container
</span>    <span class='comment'># ([OggOpus](https://wiki.xiph.org/OggOpus)).
</span>    <span class='comment'># +sample_rate_hertz+ must be one of 8000, 12000, 16000, 24000, or 48000.
</span>    <span class='const'>OGG_OPUS</span> <span class='op'>=</span> <span class='int'>6</span>

    <span class='comment'># Although the use of lossy encodings is not recommended, if a very low
</span>    <span class='comment'># bitrate encoding is required, +OGG_OPUS+ is highly preferred over
</span>    <span class='comment'># Speex encoding. The [Speex](https://speex.org/)  encoding supported by
</span>    <span class='comment'># Cloud Speech API has a header byte in each block, as in MIME type
</span>    <span class='comment'># +audio/x-speex-with-header-byte+.
</span>    <span class='comment'># It is a variant of the RTP Speex encoding defined in
</span>    <span class='comment'># [RFC 5574](https://tools.ietf.org/html/rfc5574).
</span>    <span class='comment'># The stream is a sequence of blocks, one block per RTP packet. Each block
</span>    <span class='comment'># starts with a byte containing the length of the block, in bytes, followed
</span>    <span class='comment'># by one or more frames of Speex data, padded to an integral number of
</span>    <span class='comment'># bytes (octets) as specified in RFC 5574. In other words, each RTP header
</span>    <span class='comment'># is replaced with a single byte containing the block length. Only Speex
</span>    <span class='comment'># wideband is supported. +sample_rate_hertz+ must be 16000.
</span>    <span class='const'>SPEEX_WITH_HEADER_BYTE</span> <span class='op'>=</span> <span class='int'>7</span>
  <span class='kw'>end</span>
<span class='kw'>end</span></pre>
    </td>
  </tr>
</table>
</div>
    
  </div>


</div>

  <div id="footer">
  <ul class="footer-links">
    <li>
      <a href="https://github.com/GoogleCloudPlatform/google-cloud-ruby" title="Google Cloud on Github">
        <img src="/google-cloud-ruby/img/icon-link-github.svg" alt="GitHub icon"> GitHub
      </a>
    </li>
    <li>
      <a href="https://github.com/GoogleCloudPlatform/google-cloud-ruby/issues" title="Google Cloud issues on Github">
        <img src="/google-cloud-ruby/img/icon-link-github.svg" alt="GitHub icon"> Issues
      </a>
    </li>
    <li>
      <a href="http://stackoverflow.com/questions/tagged/google-cloud-ruby" title="Google Cloud on StackOverflow">
      <img src="/google-cloud-ruby/img/icon-link-stackoverflow.svg" alt="StackOverflow icon"> StackOverflow
    </a>
    </li>
    <li>
      <a href="http://rubygems.org/gems/google-cloud" title="Google Cloud on RubyGems">
        <img src="/google-cloud-ruby/img/icon-link-package-manager.svg" alt="RubyGems icon"> RubyGems
      </a>
    </li>
  </ul>

  <p>
    Documentation generated by <a href="http://yardoc.org" title="Yay! A Ruby Documentation Tool">yard</a>.
  </p>
</div>

</div>
