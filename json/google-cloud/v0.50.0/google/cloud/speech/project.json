{"id":"google/cloud/speech/project","name":"Project","title":["Google","Cloud","Speech","Project"],"description":"<h1 id=\"project\">Project</h1>\n\n<p>The Google Cloud Speech API enables developers to convert audio to text\nby applying powerful neural network models. The API recognizes over 80\nlanguages and variants, to support your global user base. You can\ntranscribe the text of users dictating to an application’s microphone,\nenable command-and-control through voice, or transcribe audio files,\namong many other use cases. Recognize audio uploaded in the request, and\nintegrate with your audio storage on Google Cloud Storage, by using the\nsame technology Google uses to power its own products.</p>\n\n<p>See Google::Cloud#speech</p>","source":"google-cloud-speech/lib/google/cloud/speech/project.rb#L55","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\",\n                     encoding: :linear16,\n                     language: \"en-US\",\n                     sample_rate: 16000\nresults = audio.recognize\n\nresult = results.first\nresult.transcript #=> \"how old is the Brooklyn Bridge\"\nresult.confidence #=> 0.9826789498329163"}],"methods":[{"id":"project_id-instance","type":"instance","name":"project_id","title":["Google","Cloud","Speech","Project#project_id"],"description":"<p>The Speech project connected to.</p>","source":"google-cloud-speech/lib/google/cloud/speech/project.rb#L78","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new(\n  project_id: \"my-project\",\n  credentials: \"/path/to/keyfile.json\"\n)\n\nspeech.project_id #=> \"my-project\""}],"params":[],"exceptions":[],"returns":[]},{"id":"audio-instance","type":"instance","name":"audio","title":["Google","Cloud","Speech","Project#audio"],"description":"<p>Returns a new Audio instance from the given source. No API call is\nmade.</p>","source":"google-cloud-speech/lib/google/cloud/speech/project.rb#L177","resources":[{"title":"Audio Encodings","link":"https://cloud.google.com/speech/docs/basics#audio-encodings"},{"title":"Sample Rates","link":"https://cloud.google.com/speech/docs/basics#sample-rates"},{"title":"Languages","link":"https://cloud.google.com/speech/docs/basics#languages"}],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\",\n                     encoding: :linear16,\n                     language: \"en-US\",\n                     sample_rate: 16000"},{"caption":"<p>With a Google Cloud Storage URI:</p>","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"gs://bucket-name/path/to/audio.raw\",\n                     encoding: :linear16,\n                     language: \"en-US\",\n                     sample_rate: 16000"},{"caption":"<p>With a Google Cloud Storage File object:</p>","code":"require \"google/cloud/storage\"\n\nstorage = Google::Cloud::Storage.new\n\nbucket = storage.bucket \"bucket-name\"\nfile = bucket.file \"path/to/audio.raw\"\n\nrequire \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio file,\n                     encoding: :linear16,\n                     language: \"en-US\",\n                     sample_rate: 16000"}],"params":[{"name":"source","types":["String","IO","Google::Cloud::Storage::File"],"description":"A string of\nthe path to the audio file to be recognized, or a File or other IO\nobject of the audio contents, or a Cloud Storage URI of the form\n<code>\"gs://bucketname/path/to/document.ext\"</code>; or an instance of\nGoogle::Cloud::Storage::File of the text to be annotated.","optional":false,"nullable":false},{"name":"encoding","types":["String","Symbol"],"description":"Encoding of audio data to be\nrecognized. Optional.</p>\n\n<p>Acceptable values are:</p>\n\n<ul>\n  <li><code>linear16</code> - Uncompressed 16-bit signed little-endian samples.\n(LINEAR16)</li>\n  <li><code>flac</code> - The <a href=\"http://flac.sourceforge.net/documentation.html\">Free Lossless Audio\nCodec</a> encoding.\nOnly 16-bit samples are supported. Not all fields in STREAMINFO\nare supported. (FLAC)</li>\n  <li><code>mulaw</code> - 8-bit samples that compand 14-bit audio samples using\nG.711 PCMU/mu-law. (MULAW)</li>\n  <li><code>amr</code> - Adaptive Multi-Rate Narrowband codec. (<code>sample_rate</code> must\nbe 8000 Hz.) (AMR)</li>\n  <li><code>amr_wb</code> - Adaptive Multi-Rate Wideband codec. (<code>sample_rate</code> must\nbe 16000 Hz.) (AMR_WB)</li>\n  <li>\n    <p><code>ogg_opus</code> - Ogg Mapping for Opus. (OGG_OPUS)</p>\n\n    <p>Lossy codecs do not recommend, as they result in a lower-quality\nspeech transcription.</p>\n  </li>\n  <li>\n    <p><code>speex</code> - Speex with header byte. (SPEEX_WITH_HEADER_BYTE)</p>\n\n    <p>Lossy codecs do not recommend, as they result in a lower-quality\nspeech transcription. If you must use a low-bitrate encoder,\nOGG_OPUS is preferred.</p>\n  </li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"language","types":["String","Symbol"],"description":"The language of the supplied audio as\na <a href=\"https://tools.ietf.org/html/bcp47\">BCP-47</a> language code. e.g.\n“en-US” for English (United States), “en-GB” for English (United\nKingdom), “fr-FR” for French (France). See <a href=\"https://cloud.google.com/speech/docs/languages\">Language\nSupport</a> for a list\nof the currently supported language codes. Optional.","optional":true,"default":"nil","nullable":true},{"name":"sample_rate","types":["Integer"],"description":"Sample rate in Hertz of the audio data\nto be recognized. Valid values are: 8000-48000. 16000 is optimal.\nFor best results, set the sampling rate of the audio source to 16000\nHz. If that’s not possible, use the native sample rate of the audio\nsource (instead of re-sampling). Optional.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/speech/audio\">Audio</a>"],"description":"The audio file to be recognized."}]},{"id":"recognize-instance","type":"instance","name":"recognize","title":["Google","Cloud","Speech","Project#recognize"],"description":"<p>Performs synchronous speech recognition. Sends audio data to the\nSpeech API, which performs recognition on that data, and returns\nresults only after all audio has been processed. Limited to audio data\nof 1 minute or less in duration.</p>\n\n<p>The Speech API will take roughly the same amount of time to process\naudio data sent synchronously as the duration of the supplied audio\ndata. That is, if you send audio data of 30 seconds in length, expect\nthe synchronous request to take approximately 30 seconds to return\nresults.</p>","source":"google-cloud-speech/lib/google/cloud/speech/project.rb#L305","resources":[{"title":"Synchronous Speech API Recognition","link":"https://cloud.google.com/speech/docs/basics#synchronous-recognition"},{"title":"Phrase Hints","link":"https://cloud.google.com/speech/docs/basics#phrase-hints"}],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\nresults = speech.recognize \"path/to/audio.raw\",\n                           encoding: :linear16,\n                           language: \"en-US\",\n                           sample_rate: 16000"},{"caption":"<p>With a Google Cloud Storage URI:</p>","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\nresults = speech.recognize \"gs://bucket-name/path/to/audio.raw\",\n                           encoding: :linear16,\n                           language: \"en-US\",\n                           sample_rate: 16000"},{"caption":"<p>With a Google Cloud Storage File object:</p>","code":"require \"google/cloud/storage\"\n\nstorage = Google::Cloud::Storage.new\n\nbucket = storage.bucket \"bucket-name\"\nfile = bucket.file \"path/to/audio.raw\"\n\nrequire \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\nresults = speech.recognize file,\n                           encoding: :linear16,\n                           language: \"en-US\",\n                           sample_rate: 16000,\n                           max_alternatives: 10"}],"params":[{"name":"source","types":["String","IO","Google::Cloud::Storage::File"],"description":"A string of\nthe path to the audio file to be recognized, or a File or other IO\nobject of the audio contents, or a Cloud Storage URI of the form\n<code>\"gs://bucketname/path/to/document.ext\"</code>; or an instance of\nGoogle::Cloud::Storage::File of the text to be annotated.","optional":false,"nullable":false},{"name":"encoding","types":["String","Symbol"],"description":"Encoding of audio data to be\nrecognized. Optional.</p>\n\n<p>Acceptable values are:</p>\n\n<ul>\n  <li><code>linear16</code> - Uncompressed 16-bit signed little-endian samples.\n(LINEAR16)</li>\n  <li><code>flac</code> - The <a href=\"http://flac.sourceforge.net/documentation.html\">Free Lossless Audio\nCodec</a> encoding.\nOnly 16-bit samples are supported. Not all fields in STREAMINFO\nare supported. (FLAC)</li>\n  <li><code>mulaw</code> - 8-bit samples that compand 14-bit audio samples using\nG.711 PCMU/mu-law. (MULAW)</li>\n  <li><code>amr</code> - Adaptive Multi-Rate Narrowband codec. (<code>sample_rate</code> must\nbe 8000 Hz.) (AMR)</li>\n  <li><code>amr_wb</code> - Adaptive Multi-Rate Wideband codec. (<code>sample_rate</code> must\nbe 16000 Hz.) (AMR_WB)</li>\n  <li>\n    <p><code>ogg_opus</code> - Ogg Mapping for Opus. (OGG_OPUS)</p>\n\n    <p>Lossy codecs do not recommend, as they result in a lower-quality\nspeech transcription.</p>\n  </li>\n  <li>\n    <p><code>speex</code> - Speex with header byte. (SPEEX_WITH_HEADER_BYTE)</p>\n\n    <p>Lossy codecs do not recommend, as they result in a lower-quality\nspeech transcription. If you must use a low-bitrate encoder,\nOGG_OPUS is preferred.</p>\n  </li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"language","types":["String","Symbol"],"description":"The language of the supplied audio as\na <a href=\"https://tools.ietf.org/html/bcp47\">BCP-47</a> language code. e.g.\n“en-US” for English (United States), “en-GB” for English (United\nKingdom), “fr-FR” for French (France). See <a href=\"https://cloud.google.com/speech/docs/languages\">Language\nSupport</a> for a list\nof the currently supported language codes. Optional.","optional":true,"default":"nil","nullable":true},{"name":"sample_rate","types":["Integer"],"description":"Sample rate in Hertz of the audio data\nto be recognized. Valid values are: 8000-48000. 16000 is optimal.\nFor best results, set the sampling rate of the audio source to 16000\nHz. If that’s not possible, use the native sample rate of the audio\nsource (instead of re-sampling). Optional.","optional":true,"default":"nil","nullable":true},{"name":"max_alternatives","types":["String"],"description":"The Maximum number of recognition\nhypotheses to be returned. Default is 1. The service may return\nfewer. Valid values are 0-30. Defaults to 1. Optional.","optional":true,"default":"nil","nullable":true},{"name":"profanity_filter","types":["Boolean"],"description":"When <code>true</code>, the service will\nattempt to filter out profanities, replacing all but the initial\ncharacter in each filtered word with asterisks, e.g. “f***”. Default\nis <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"phrases","types":["Array<String>"],"description":"A list of strings containing words and\nphrases “hints” so that the speech recognition is more likely to\nrecognize them. See <a href=\"https://cloud.google.com/speech/limits#content\">usage\nlimits</a>. Optional.","optional":true,"default":"nil","nullable":true},{"name":"words","types":["Boolean"],"description":"When <code>true</code>, return a list of words with\nadditional information about each word. Currently, the only\nadditional information provided is the the start and end time\noffsets. See <a data-custom-type=\"google/cloud/speech/result\" data-method=\"words-instance\">Result#words</a>. Default is <code>false</code>.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["Array&lt;<a data-custom-type=\"google/cloud/speech/result\">Result</a>&gt;"],"description":"The transcribed text of audio recognized."}]},{"id":"process-instance","type":"instance","name":"process","title":["Google","Cloud","Speech","Project#process"],"description":"<p>Performs asynchronous speech recognition. Requests are processed\nasynchronously, meaning a Operation is returned once the audio data\nhas been sent, and can be refreshed to retrieve recognition results\nonce the audio data has been processed.</p>","source":"google-cloud-speech/lib/google/cloud/speech/project.rb#L444","resources":[{"title":"Asynchronous Speech API Responses","link":"https://cloud.google.com/speech/docs/basics#async-responses"}],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\nop = speech.process \"path/to/audio.raw\",\n                    encoding: :linear16,\n                    language: \"en-US\",\n                    sample_rate: 16000\n\nop.done? #=> false\nop.reload!"},{"caption":"<p>With a Google Cloud Storage URI:</p>","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\nop = speech.process \"gs://bucket-name/path/to/audio.raw\",\n                    encoding: :linear16,\n                    language: \"en-US\",\n                    sample_rate: 16000\n\nop.done? #=> false\nop.reload!"},{"caption":"<p>With a Google Cloud Storage File object:</p>","code":"require \"google/cloud/storage\"\n\nstorage = Google::Cloud::Storage.new\n\nbucket = storage.bucket \"bucket-name\"\nfile = bucket.file \"path/to/audio.raw\"\n\nrequire \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\nop = speech.process file,\n                    encoding: :linear16,\n                    language: \"en-US\",\n                    sample_rate: 16000,\n                    max_alternatives: 10\n\nop.done? #=> false\nop.reload!"}],"params":[{"name":"source","types":["String","IO","Google::Cloud::Storage::File"],"description":"A string of\nthe path to the audio file to be recognized, or a File or other IO\nobject of the audio contents, or a Cloud Storage URI of the form\n<code>\"gs://bucketname/path/to/document.ext\"</code>; or an instance of\nGoogle::Cloud::Storage::File of the text to be annotated.","optional":false,"nullable":false},{"name":"encoding","types":["String","Symbol"],"description":"Encoding of audio data to be\nrecognized. Optional.</p>\n\n<p>Acceptable values are:</p>\n\n<ul>\n  <li><code>linear16</code> - Uncompressed 16-bit signed little-endian samples.\n(LINEAR16)</li>\n  <li><code>flac</code> - The <a href=\"http://flac.sourceforge.net/documentation.html\">Free Lossless Audio\nCodec</a> encoding.\nOnly 16-bit samples are supported. Not all fields in STREAMINFO\nare supported. (FLAC)</li>\n  <li><code>mulaw</code> - 8-bit samples that compand 14-bit audio samples using\nG.711 PCMU/mu-law. (MULAW)</li>\n  <li><code>amr</code> - Adaptive Multi-Rate Narrowband codec. (<code>sample_rate</code> must\nbe 8000 Hz.) (AMR)</li>\n  <li><code>amr_wb</code> - Adaptive Multi-Rate Wideband codec. (<code>sample_rate</code> must\nbe 16000 Hz.) (AMR_WB)</li>\n  <li>\n    <p><code>ogg_opus</code> - Ogg Mapping for Opus. (OGG_OPUS)</p>\n\n    <p>Lossy codecs do not recommend, as they result in a lower-quality\nspeech transcription.</p>\n  </li>\n  <li>\n    <p><code>speex</code> - Speex with header byte. (SPEEX_WITH_HEADER_BYTE)</p>\n\n    <p>Lossy codecs do not recommend, as they result in a lower-quality\nspeech transcription. If you must use a low-bitrate encoder,\nOGG_OPUS is preferred.</p>\n  </li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"language","types":["String","Symbol"],"description":"The language of the supplied audio as\na <a href=\"https://tools.ietf.org/html/bcp47\">BCP-47</a> language code. e.g.\n“en-US” for English (United States), “en-GB” for English (United\nKingdom), “fr-FR” for French (France). See <a href=\"https://cloud.google.com/speech/docs/languages\">Language\nSupport</a> for a list\nof the currently supported language codes. Optional.","optional":true,"default":"nil","nullable":true},{"name":"sample_rate","types":["Integer"],"description":"Sample rate in Hertz of the audio data\nto be recognized. Valid values are: 8000-48000. 16000 is optimal.\nFor best results, set the sampling rate of the audio source to 16000\nHz. If that’s not possible, use the native sample rate of the audio\nsource (instead of re-sampling). Optional.","optional":true,"default":"nil","nullable":true},{"name":"max_alternatives","types":["String"],"description":"The Maximum number of recognition\nhypotheses to be returned. Default is 1. The service may return\nfewer. Valid values are 0-30. Defaults to 1. Optional.","optional":true,"default":"nil","nullable":true},{"name":"profanity_filter","types":["Boolean"],"description":"When <code>true</code>, the service will\nattempt to filter out profanities, replacing all but the initial\ncharacter in each filtered word with asterisks, e.g. “f***”. Default\nis <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"phrases","types":["Array<String>"],"description":"A list of strings containing words and\nphrases “hints” so that the speech recognition is more likely to\nrecognize them. See <a href=\"https://cloud.google.com/speech/limits#content\">usage\nlimits</a>. Optional.","optional":true,"default":"nil","nullable":true},{"name":"words","types":["Boolean"],"description":"When <code>true</code>, return a list of words with\nadditional information about each word. Currently, the only\nadditional information provided is the the start and end time\noffsets. See <a data-custom-type=\"google/cloud/speech/result\" data-method=\"words-instance\">Result#words</a>. Default is <code>false</code>.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/speech/operation\">Operation</a>"],"description":"A resource represents the long-running,\nasynchronous processing of a speech-recognition operation."}]},{"id":"stream-instance","type":"instance","name":"stream","title":["Google","Cloud","Speech","Project#stream"],"description":"<p>Creates a Stream object to perform bidirectional streaming\nspeech-recognition: receive results while sending audio.</p>","source":"google-cloud-speech/lib/google/cloud/speech/project.rb#L560","resources":[{"title":"Streaming Speech API Recognition Requests","link":"https://cloud.google.com/speech/docs/basics#streaming-recognition"}],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\nstream = speech.stream encoding: :linear16,\n                       language: \"en-US\",\n                       sample_rate: 16000\n\n# Stream 5 seconds of audio from the microphone\n# Actual implementation of microphone input varies by platform\n5.times do\n  stream.send MicrophoneInput.read(32000)\nend\n\nstream.stop\nstream.wait_until_complete!\n\nresults = stream.results\nresult = results.first\nresult.transcript #=> \"how old is the Brooklyn Bridge\"\nresult.confidence #=> 0.9826789498329163"}],"params":[{"name":"encoding","types":["String","Symbol"],"description":"Encoding of audio data to be\nrecognized. Optional.</p>\n\n<p>Acceptable values are:</p>\n\n<ul>\n  <li><code>linear16</code> - Uncompressed 16-bit signed little-endian samples.\n(LINEAR16)</li>\n  <li><code>flac</code> - The <a href=\"http://flac.sourceforge.net/documentation.html\">Free Lossless Audio\nCodec</a> encoding.\nOnly 16-bit samples are supported. Not all fields in STREAMINFO\nare supported. (FLAC)</li>\n  <li><code>mulaw</code> - 8-bit samples that compand 14-bit audio samples using\nG.711 PCMU/mu-law. (MULAW)</li>\n  <li><code>amr</code> - Adaptive Multi-Rate Narrowband codec. (<code>sample_rate</code> must\nbe 8000 Hz.) (AMR)</li>\n  <li><code>amr_wb</code> - Adaptive Multi-Rate Wideband codec. (<code>sample_rate</code> must\nbe 16000 Hz.) (AMR_WB)</li>\n  <li>\n    <p><code>ogg_opus</code> - Ogg Mapping for Opus. (OGG_OPUS)</p>\n\n    <p>Lossy codecs do not recommend, as they result in a lower-quality\nspeech transcription.</p>\n  </li>\n  <li>\n    <p><code>speex</code> - Speex with header byte. (SPEEX_WITH_HEADER_BYTE)</p>\n\n    <p>Lossy codecs do not recommend, as they result in a lower-quality\nspeech transcription. If you must use a low-bitrate encoder,\nOGG_OPUS is preferred.</p>\n  </li>\n</ul>","optional":true,"default":"nil","nullable":true},{"name":"language","types":["String","Symbol"],"description":"The language of the supplied audio as\na <a href=\"https://tools.ietf.org/html/bcp47\">BCP-47</a> language code. e.g.\n“en-US” for English (United States), “en-GB” for English (United\nKingdom), “fr-FR” for French (France). See <a href=\"https://cloud.google.com/speech/docs/languages\">Language\nSupport</a> for a list\nof the currently supported language codes. Optional.","optional":true,"default":"nil","nullable":true},{"name":"sample_rate","types":["Integer"],"description":"Sample rate in Hertz of the audio data\nto be recognized. Valid values are: 8000-48000. 16000 is optimal.\nFor best results, set the sampling rate of the audio source to 16000\nHz. If that’s not possible, use the native sample rate of the audio\nsource (instead of re-sampling). Optional.","optional":true,"default":"nil","nullable":true},{"name":"max_alternatives","types":["String"],"description":"The Maximum number of recognition\nhypotheses to be returned. Default is 1. The service may return\nfewer. Valid values are 0-30. Defaults to 1. Optional.","optional":true,"default":"nil","nullable":true},{"name":"profanity_filter","types":["Boolean"],"description":"When <code>true</code>, the service will\nattempt to filter out profanities, replacing all but the initial\ncharacter in each filtered word with asterisks, e.g. “f***”. Default\nis <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"phrases","types":["Array<String>"],"description":"A list of strings containing words and\nphrases “hints” so that the speech recognition is more likely to\nrecognize them. See <a href=\"https://cloud.google.com/speech/limits#content\">usage\nlimits</a>. Optional.","optional":true,"default":"nil","nullable":true},{"name":"words","types":["Boolean"],"description":"When <code>true</code>, return a list of words with\nadditional information about each word. Currently, the only\nadditional information provided is the the start and end time\noffsets. See <a data-custom-type=\"google/cloud/speech/result\" data-method=\"words-instance\">Result#words</a>. Default is <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"utterance","types":["Boolean"],"description":"When <code>true</code>, the service will perform\ncontinuous recognition (continuing to process audio even if the user\npauses speaking) until the client closes the output stream (gRPC\nAPI) or when the maximum time limit has been reached. Default is\n<code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"interim","types":["Boolean"],"description":"When <code>true</code>, interim results (tentative\nhypotheses) may be returned as they become available. Default is\n<code>false</code>.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/speech/stream\">Stream</a>"],"description":"A resource that represents the streaming requests and\nresponses."}]},{"id":"operation-instance","type":"instance","name":"operation","title":["Google","Cloud","Speech","Project#operation"],"description":"<p>Performs asynchronous speech recognition. Requests are processed\nasynchronously, meaning a Operation is returned once the audio data\nhas been sent, and can be refreshed to retrieve recognition results\nonce the audio data has been processed.</p>","source":"google-cloud-speech/lib/google/cloud/speech/project.rb#L609","resources":[{"title":"Long-running Operation","link":"https://cloud.google.com/speech/reference/rpc/google.longrunning#google.longrunning.Operations"}],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\nop = speech.operation \"1234567890\"\n\nop.done? #=> false\nop.reload!"}],"params":[{"name":"id","types":["String"],"description":"The unique identifier for the long running\noperation. Required.","optional":false,"nullable":false}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/speech/operation\">Operation</a>"],"description":"A resource represents the long-running,\nasynchronous processing of a speech-recognition operation."}]}]}