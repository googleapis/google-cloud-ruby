{"id":"google/cloud/speech/audio","name":"Audio","title":["Google","Cloud","Speech","Audio"],"description":"<h1 id=\"audio\">Audio</h1>\n\n<p>Represents a source of audio data, with related metadata such as the\n<a href=\"https://cloud.google.com/speech/docs/basics#audio-encodings\">audio encoding</a>,\n<a href=\"https://cloud.google.com/speech/docs/basics#sample-rates\">sample rate</a>,\nand <a href=\"https://cloud.google.com/speech/docs/basics#languages\">language</a>.</p>\n\n<p>See <a data-custom-type=\"google/cloud/speech/project\" data-method=\"audio-instance\">Project#audio</a>.</p>","source":"google-cloud-speech/lib/google/cloud/speech/audio.rb#L51","resources":[{"title":"Audio Encodings","link":"https://cloud.google.com/speech/docs/basics#audio-encodings"},{"title":"Sample Rates","link":"https://cloud.google.com/speech/docs/basics#sample-rates"},{"title":"Languages","link":"https://cloud.google.com/speech/docs/basics#languages"}],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\",\n                     encoding: :linear16,\n                     language: \"en-US\",\n                     sample_rate: 16000\n\nresults = audio.recognize\nresult = results.first\nresult.transcript #=> \"how old is the Brooklyn Bridge\"\nresult.confidence #=> 0.9826789498329163"}],"methods":[{"id":"encoding-instance","type":"instance","name":"encoding","title":["Google","Cloud","Speech","Audio#encoding"],"description":"<p>Encoding of audio data to be recognized.</p>\n\n<p>Acceptable values are:</p>\n\n<ul>\n  <li><code>linear16</code> - Uncompressed 16-bit signed little-endian samples.\n(LINEAR16)</li>\n  <li><code>flac</code> - The <a href=\"http://flac.sourceforge.net/documentation.html\">Free Lossless Audio\nCodec</a> encoding.\nOnly 16-bit samples are supported. Not all fields in STREAMINFO\nare supported. (FLAC)</li>\n  <li><code>mulaw</code> - 8-bit samples that compand 14-bit audio samples using\nG.711 PCMU/mu-law. (MULAW)</li>\n  <li><code>amr</code> - Adaptive Multi-Rate Narrowband codec. (<code>sample_rate</code> must\nbe 8000 Hz.) (AMR)</li>\n  <li><code>amr_wb</code> - Adaptive Multi-Rate Wideband codec. (<code>sample_rate</code> must\nbe 16000 Hz.) (AMR_WB)</li>\n  <li>\n    <p><code>ogg_opus</code> - Ogg Mapping for Opus. (OGG_OPUS)</p>\n\n    <p>Lossy codecs do not recommend, as they result in a lower-quality\nspeech transcription.</p>\n  </li>\n  <li>\n    <p><code>speex</code> - Speex with header byte. (SPEEX_WITH_HEADER_BYTE)</p>\n\n    <p>Lossy codecs do not recommend, as they result in a lower-quality\nspeech transcription. If you must use a low-bitrate encoder,\nOGG_OPUS is preferred.</p>\n  </li>\n</ul>","source":"google-cloud-speech/lib/google/cloud/speech/audio.rb#L98","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\",\n                     language: \"en-US\",\n                     sample_rate: 16000\n\naudio.encoding = :linear16\naudio.encoding #=> :linear16"}],"params":[],"exceptions":[],"returns":[{"types":["String","Symbol"],"description":""}]},{"id":"encoding=-instance","type":"instance","name":"encoding=","title":["Google","Cloud","Speech","Audio#encoding="],"description":"<p>Encoding of audio data to be recognized.</p>\n\n<p>Acceptable values are:</p>\n\n<ul>\n  <li><code>linear16</code> - Uncompressed 16-bit signed little-endian samples.\n(LINEAR16)</li>\n  <li><code>flac</code> - The <a href=\"http://flac.sourceforge.net/documentation.html\">Free Lossless Audio\nCodec</a> encoding.\nOnly 16-bit samples are supported. Not all fields in STREAMINFO\nare supported. (FLAC)</li>\n  <li><code>mulaw</code> - 8-bit samples that compand 14-bit audio samples using\nG.711 PCMU/mu-law. (MULAW)</li>\n  <li><code>amr</code> - Adaptive Multi-Rate Narrowband codec. (<code>sample_rate</code> must\nbe 8000 Hz.) (AMR)</li>\n  <li><code>amr_wb</code> - Adaptive Multi-Rate Wideband codec. (<code>sample_rate</code> must\nbe 16000 Hz.) (AMR_WB)</li>\n  <li>\n    <p><code>ogg_opus</code> - Ogg Mapping for Opus. (OGG_OPUS)</p>\n\n    <p>Lossy codecs do not recommend, as they result in a lower-quality\nspeech transcription.</p>\n  </li>\n  <li>\n    <p><code>speex</code> - Speex with header byte. (SPEEX_WITH_HEADER_BYTE)</p>\n\n    <p>Lossy codecs do not recommend, as they result in a lower-quality\nspeech transcription. If you must use a low-bitrate encoder,\nOGG_OPUS is preferred.</p>\n  </li>\n</ul>","source":"google-cloud-speech/lib/google/cloud/speech/audio.rb#L98","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\",\n                     language: \"en-US\",\n                     sample_rate: 16000\n\naudio.encoding = :linear16\naudio.encoding #=> :linear16"}],"params":[],"exceptions":[],"returns":[{"types":["String","Symbol"],"description":""}]},{"id":"language-instance","type":"instance","name":"language","title":["Google","Cloud","Speech","Audio#language"],"description":"<p>The language of the supplied audio as a\n<a href=\"https://tools.ietf.org/html/bcp47\">BCP-47</a> language code. e.g.\n“en-US” for English (United States), “en-GB” for English (United\nKingdom), “fr-FR” for French (France). See <a href=\"https://cloud.google.com/speech/docs/languages\">Language\nSupport</a> for a list of\nthe currently supported language codes.</p>","source":"google-cloud-speech/lib/google/cloud/speech/audio.rb#L122","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\",\n                     encoding: :linear16,\n                     sample_rate: 16000\n\naudio.language = \"en-US\"\naudio.language #=> \"en-US\""}],"params":[],"exceptions":[],"returns":[{"types":["String","Symbol"],"description":""}]},{"id":"language=-instance","type":"instance","name":"language=","title":["Google","Cloud","Speech","Audio#language="],"description":"<p>The language of the supplied audio as a\n<a href=\"https://tools.ietf.org/html/bcp47\">BCP-47</a> language code. e.g.\n“en-US” for English (United States), “en-GB” for English (United\nKingdom), “fr-FR” for French (France). See <a href=\"https://cloud.google.com/speech/docs/languages\">Language\nSupport</a> for a list of\nthe currently supported language codes.</p>","source":"google-cloud-speech/lib/google/cloud/speech/audio.rb#L122","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\",\n                     encoding: :linear16,\n                     sample_rate: 16000\n\naudio.language = \"en-US\"\naudio.language #=> \"en-US\""}],"params":[],"exceptions":[],"returns":[{"types":["String","Symbol"],"description":""}]},{"id":"sample_rate-instance","type":"instance","name":"sample_rate","title":["Google","Cloud","Speech","Audio#sample_rate"],"description":"<p>Sample rate in Hertz of the audio data to be recognized. Valid values\nare: 8000-48000. 16000 is optimal. For best results, set the sampling\nrate of the audio source to 16000 Hz. If that’s not possible, use the\nnative sample rate of the audio source (instead of re-sampling).</p>","source":"google-cloud-speech/lib/google/cloud/speech/audio.rb#L144","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\",\n                     encoding: :linear16,\n                     language: \"en-US\"\n\naudio.sample_rate = 16000\naudio.sample_rate #=> 16000"}],"params":[],"exceptions":[],"returns":[{"types":["Integer"],"description":""}]},{"id":"sample_rate=-instance","type":"instance","name":"sample_rate=","title":["Google","Cloud","Speech","Audio#sample_rate="],"description":"<p>Sample rate in Hertz of the audio data to be recognized. Valid values\nare: 8000-48000. 16000 is optimal. For best results, set the sampling\nrate of the audio source to 16000 Hz. If that’s not possible, use the\nnative sample rate of the audio source (instead of re-sampling).</p>","source":"google-cloud-speech/lib/google/cloud/speech/audio.rb#L144","resources":[],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\",\n                     encoding: :linear16,\n                     language: \"en-US\"\n\naudio.sample_rate = 16000\naudio.sample_rate #=> 16000"}],"params":[],"exceptions":[],"returns":[{"types":["Integer"],"description":""}]},{"id":"recognize-instance","type":"instance","name":"recognize","title":["Google","Cloud","Speech","Audio#recognize"],"description":"<p>Performs synchronous speech recognition. Sends audio data to the\nSpeech API, which performs recognition on that data, and returns\nresults only after all audio has been processed. Limited to audio data\nof 1 minute or less in duration.</p>\n\n<p>The Speech API will take roughly the same amount of time to process\naudio data sent synchronously as the duration of the supplied audio\ndata. That is, if you send audio data of 30 seconds in length, expect\nthe synchronous request to take approximately 30 seconds to return\nresults.</p>","source":"google-cloud-speech/lib/google/cloud/speech/audio.rb#L216","resources":[{"title":"Synchronous Speech API Recognition","link":"https://cloud.google.com/speech/docs/basics#synchronous-recognition"},{"title":"Phrase Hints","link":"https://cloud.google.com/speech/docs/basics#phrase-hints"}],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\",\n                     encoding: :linear16,\n                     language: \"en-US\",\n                     sample_rate: 16000\n\nresults = audio.recognize\nresult = results.first\nresult.transcript #=> \"how old is the Brooklyn Bridge\"\nresult.confidence #=> 0.9826789498329163"}],"params":[{"name":"max_alternatives","types":["String"],"description":"The Maximum number of recognition\nhypotheses to be returned. Default is 1. The service may return\nfewer. Valid values are 0-30. Defaults to 1. Optional.","optional":true,"default":"nil","nullable":true},{"name":"profanity_filter","types":["Boolean"],"description":"When <code>true</code>, the service will\nattempt to filter out profanities, replacing all but the initial\ncharacter in each filtered word with asterisks, e.g. “f***”. Default\nis <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"phrases","types":["Array<String>"],"description":"A list of strings containing words and\nphrases “hints” so that the speech recognition is more likely to\nrecognize them. See <a href=\"https://cloud.google.com/speech/limits#content\">usage\nlimits</a>. Optional.","optional":true,"default":"nil","nullable":true},{"name":"words","types":["Boolean"],"description":"When <code>true</code>, return a list of words with\nadditional information about each word. Currently, the only\nadditional information provided is the the start and end time\noffsets. See <a data-custom-type=\"google/cloud/speech/result\" data-method=\"words-instance\">Result#words</a>. Default is <code>false</code>.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["Array&lt;<a data-custom-type=\"google/cloud/speech/result\">Result</a>&gt;"],"description":"The transcribed text of audio recognized."}]},{"id":"process-instance","type":"instance","name":"process","title":["Google","Cloud","Speech","Audio#process"],"description":"<p>Performs asynchronous speech recognition. Requests are processed\nasynchronously, meaning a Operation is returned once the audio data\nhas been sent, and can be refreshed to retrieve recognition results\nonce the audio data has been processed.</p>","source":"google-cloud-speech/lib/google/cloud/speech/audio.rb#L271","resources":[{"title":"Asynchronous Speech API Responses","link":"https://cloud.google.com/speech/docs/basics#async-responses"}],"examples":[{"caption":"","code":"require \"google/cloud/speech\"\n\nspeech = Google::Cloud::Speech.new\n\naudio = speech.audio \"path/to/audio.raw\",\n                     encoding: :linear16,\n                     language: \"en-US\",\n                     sample_rate: 16000\n\nop = audio.process\nop.done? #=> false\nop.reload!\nop.done? #=> true\nresults = op.results"}],"params":[{"name":"max_alternatives","types":["String"],"description":"The Maximum number of recognition\nhypotheses to be returned. Default is 1. The service may return\nfewer. Valid values are 0-30. Defaults to 1. Optional.","optional":true,"default":"nil","nullable":true},{"name":"profanity_filter","types":["Boolean"],"description":"When <code>true</code>, the service will\nattempt to filter out profanities, replacing all but the initial\ncharacter in each filtered word with asterisks, e.g. “f***”. Default\nis <code>false</code>.","optional":true,"default":"nil","nullable":true},{"name":"phrases","types":["Array<String>"],"description":"A list of strings containing words and\nphrases “hints” so that the speech recognition is more likely to\nrecognize them. See <a href=\"https://cloud.google.com/speech/limits#content\">usage\nlimits</a>. Optional.","optional":true,"default":"nil","nullable":true},{"name":"words","types":["Boolean"],"description":"When <code>true</code>, return a list of words with\nadditional information about each word. Currently, the only\nadditional information provided is the the start and end time\noffsets. See <a data-custom-type=\"google/cloud/speech/result\" data-method=\"words-instance\">Result#words</a>. Default is <code>false</code>.","optional":true,"default":"nil","nullable":true}],"exceptions":[],"returns":[{"types":["<a data-custom-type=\"google/cloud/speech/operation\">Operation</a>"],"description":"A resource represents the long-running,\nasynchronous processing of a speech-recognition operation."}]}]}