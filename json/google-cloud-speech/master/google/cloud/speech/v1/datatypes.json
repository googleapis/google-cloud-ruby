{"id":"google/cloud/speech/v1/datatypes","name":"DataTypes","title":["Google","Cloud","Speech","V1","DataTypes"],"description":"<h4>Google::Protobuf</h4>\n\n<table class=\"table\">\n  <thead>\n    <tr>\n      <th>Class</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n\n    <tr>\n      <td><a data-custom-type=\"google/protobuf/any\">Google::Protobuf::Any</a></td>\n      <td>+Any+ contains an arbitrary serialized protocol buffer message along with a\nURL that describes the type of the serialized message.</td>\n    </tr>\n\n    <tr>\n      <td><a data-custom-type=\"google/protobuf/duration\">Google::Protobuf::Duration</a></td>\n      <td>A Duration represents a signed, fixed-length span of time represented\nas a count of seconds and fractions of seconds at nanosecond\nresolution.</td>\n    </tr>\n\n  </tbody>\n</table>\n<h4>Google::Rpc</h4>\n\n<table class=\"table\">\n  <thead>\n    <tr>\n      <th>Class</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n\n    <tr>\n      <td><a data-custom-type=\"google/rpc/status\">Google::Rpc::Status</a></td>\n      <td>The +Status+ type defines a logical error model that is suitable for different\nprogramming environments, including REST APIs and RPC APIs.</td>\n    </tr>\n\n  </tbody>\n</table>\n<h4>Google::Cloud::Speech::V1</h4>\n\n<table class=\"table\">\n  <thead>\n    <tr>\n      <th>Class</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n\n    <tr>\n      <td><a data-custom-type=\"google/cloud/speech/v1/longrunningrecognizemetadata\">Google::Cloud::Speech::V1::LongRunningRecognizeMetadata</a></td>\n      <td>Describes the progress of a long-running +LongRunningRecognize+ call.</td>\n    </tr>\n\n    <tr>\n      <td><a data-custom-type=\"google/cloud/speech/v1/longrunningrecognizeresponse\">Google::Cloud::Speech::V1::LongRunningRecognizeResponse</a></td>\n      <td>The only message returned to the client by the +LongRunningRecognize+ method.</td>\n    </tr>\n\n    <tr>\n      <td><a data-custom-type=\"google/cloud/speech/v1/recognitionaudio\">Google::Cloud::Speech::V1::RecognitionAudio</a></td>\n      <td>Contains audio data in the encoding specified in the +RecognitionConfig+.</td>\n    </tr>\n\n    <tr>\n      <td><a data-custom-type=\"google/cloud/speech/v1/recognitionconfig/audioencoding\">Google::Cloud::Speech::V1::RecognitionConfig::AudioEncoding</a></td>\n      <td>Audio encoding of the data sent in the audio message.</td>\n    </tr>\n\n    <tr>\n      <td><a data-custom-type=\"google/cloud/speech/v1/recognizeresponse\">Google::Cloud::Speech::V1::RecognizeResponse</a></td>\n      <td>The only message returned to the client by the +Recognize+ method.</td>\n    </tr>\n\n    <tr>\n      <td><a data-custom-type=\"google/cloud/speech/v1/speech/service\">Google::Cloud::Speech::V1::Speech::Service</a></td>\n      <td>Service that implements Google Cloud Speech API.</td>\n    </tr>\n\n    <tr>\n      <td><a data-custom-type=\"google/cloud/speech/v1/speechcontext\">Google::Cloud::Speech::V1::SpeechContext</a></td>\n      <td>Provides “hints” to the speech recognizer to favor specific words and phrases\nin the results.</td>\n    </tr>\n\n    <tr>\n      <td><a data-custom-type=\"google/cloud/speech/v1/speechrecognitionalternative\">Google::Cloud::Speech::V1::SpeechRecognitionAlternative</a></td>\n      <td>Alternative hypotheses (a.k.a.</td>\n    </tr>\n\n    <tr>\n      <td><a data-custom-type=\"google/cloud/speech/v1/speechrecognitionresult\">Google::Cloud::Speech::V1::SpeechRecognitionResult</a></td>\n      <td>A speech recognition result corresponding to a portion of the audio.</td>\n    </tr>\n\n    <tr>\n      <td><a data-custom-type=\"google/cloud/speech/v1/streamingrecognitionresult\">Google::Cloud::Speech::V1::StreamingRecognitionResult</a></td>\n      <td>A streaming speech recognition result corresponding to a portion of the audio\nthat is currently being processed.</td>\n    </tr>\n\n    <tr>\n      <td><a data-custom-type=\"google/cloud/speech/v1/streamingrecognizeresponse\">Google::Cloud::Speech::V1::StreamingRecognizeResponse</a></td>\n      <td>+StreamingRecognizeResponse+ is the only message returned to the client by\n+StreamingRecognize+.</td>\n    </tr>\n\n    <tr>\n      <td><a data-custom-type=\"google/cloud/speech/v1/streamingrecognizeresponse/speecheventtype\">Google::Cloud::Speech::V1::StreamingRecognizeResponse::SpeechEventType</a></td>\n      <td>Indicates the type of speech event.</td>\n    </tr>\n\n    <tr>\n      <td><a data-custom-type=\"google/cloud/speech/v1/wordinfo\">Google::Cloud::Speech::V1::WordInfo</a></td>\n      <td>Word-specific information for recognized words.</td>\n    </tr>\n\n  </tbody>\n</table>\n\n","source":"","resources":[],"examples":[],"methods":[]}