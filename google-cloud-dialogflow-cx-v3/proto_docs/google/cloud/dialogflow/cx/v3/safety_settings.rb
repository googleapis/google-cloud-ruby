# frozen_string_literal: true

# Copyright 2023 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Auto-generated by gapic-generator-ruby. DO NOT EDIT!


module Google
  module Cloud
    module Dialogflow
      module CX
        module V3
          # Settings for Generative Safety.
          # @!attribute [rw] default_banned_phrase_match_strategy
          #   @return [::Google::Cloud::Dialogflow::CX::V3::SafetySettings::PhraseMatchStrategy]
          #     Optional. Default phrase match strategy for banned phrases.
          # @!attribute [rw] banned_phrases
          #   @return [::Array<::Google::Cloud::Dialogflow::CX::V3::SafetySettings::Phrase>]
          #     Banned phrases for generated text.
          # @!attribute [rw] rai_settings
          #   @return [::Google::Cloud::Dialogflow::CX::V3::SafetySettings::RaiSettings]
          #     Optional. Settings for Responsible AI checks.
          # @!attribute [rw] default_rai_settings
          #   @return [::Google::Cloud::Dialogflow::CX::V3::SafetySettings::RaiSettings]
          #     Optional. Immutable. Default RAI settings to be annotated on the agent, so
          #     that users will be able to restore their RAI configurations to the default
          #     settings. Read-only field for the API proto only.
          # @!attribute [rw] prompt_security_settings
          #   @return [::Google::Cloud::Dialogflow::CX::V3::SafetySettings::PromptSecuritySettings]
          #     Optional. Settings for prompt security checks.
          class SafetySettings
            include ::Google::Protobuf::MessageExts
            extend ::Google::Protobuf::MessageExts::ClassMethods

            # Text input which can be used for prompt or banned phrases.
            # @!attribute [rw] text
            #   @return [::String]
            #     Required. Text input which can be used for prompt or banned phrases.
            # @!attribute [rw] language_code
            #   @return [::String]
            #     Required. Language code of the phrase.
            class Phrase
              include ::Google::Protobuf::MessageExts
              extend ::Google::Protobuf::MessageExts::ClassMethods
            end

            # Settings for Responsible AI.
            # @!attribute [rw] category_filters
            #   @return [::Array<::Google::Cloud::Dialogflow::CX::V3::SafetySettings::RaiSettings::CategoryFilter>]
            #     Optional. RAI blocking configurations.
            class RaiSettings
              include ::Google::Protobuf::MessageExts
              extend ::Google::Protobuf::MessageExts::ClassMethods

              # Configuration of the sensitivity level for blocking an RAI category.
              # @!attribute [rw] category
              #   @return [::Google::Cloud::Dialogflow::CX::V3::SafetySettings::RaiSettings::SafetyCategory]
              #     RAI category to configure.
              # @!attribute [rw] filter_level
              #   @return [::Google::Cloud::Dialogflow::CX::V3::SafetySettings::RaiSettings::SafetyFilterLevel]
              #     Blocking sensitivity level to configure for the RAI category.
              class CategoryFilter
                include ::Google::Protobuf::MessageExts
                extend ::Google::Protobuf::MessageExts::ClassMethods
              end

              # Sensitivity level for RAI categories.
              module SafetyFilterLevel
                # Unspecified -- uses default sensitivity levels.
                SAFETY_FILTER_LEVEL_UNSPECIFIED = 0

                # Block no text -- effectively disables the category.
                BLOCK_NONE = 1

                # Block a few suspicious texts.
                BLOCK_FEW = 2

                # Block some suspicious texts.
                BLOCK_SOME = 3

                # Block most suspicious texts.
                BLOCK_MOST = 4
              end

              # RAI categories to configure.
              module SafetyCategory
                # Unspecified.
                SAFETY_CATEGORY_UNSPECIFIED = 0

                # Dangerous content.
                DANGEROUS_CONTENT = 1

                # Hate speech.
                HATE_SPEECH = 2

                # Harassment.
                HARASSMENT = 3

                # Sexually explicit content.
                SEXUALLY_EXPLICIT_CONTENT = 4
              end
            end

            # Settings for prompt security checks.
            # @!attribute [rw] enable_prompt_security
            #   @return [::Boolean]
            #     Optional. Enable prompt security checks.
            class PromptSecuritySettings
              include ::Google::Protobuf::MessageExts
              extend ::Google::Protobuf::MessageExts::ClassMethods
            end

            # Strategy for matching phrases.
            module PhraseMatchStrategy
              # Unspecified, defaults to PARTIAL_MATCH.
              PHRASE_MATCH_STRATEGY_UNSPECIFIED = 0

              # Text that contains the phrase as a substring will be matched, e.g. "foo"
              # will match "afoobar".
              PARTIAL_MATCH = 1

              # Text that contains the tokenized words of the phrase will be matched,
              # e.g. "foo" will match "a foo bar" and "foo bar", but not "foobar".
              WORD_MATCH = 2
            end
          end
        end
      end
    end
  end
end
