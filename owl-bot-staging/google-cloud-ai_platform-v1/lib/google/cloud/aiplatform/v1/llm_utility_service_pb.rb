# frozen_string_literal: true
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: google/cloud/aiplatform/v1/llm_utility_service.proto

require 'google/protobuf'

require 'google/api/annotations_pb'
require 'google/api/client_pb'
require 'google/api/field_behavior_pb'
require 'google/api/resource_pb'
require 'google/cloud/aiplatform/v1/prediction_service_pb'
require 'google/protobuf/struct_pb'


descriptor_data = "\n4google/cloud/aiplatform/v1/llm_utility_service.proto\x12\x1agoogle.cloud.aiplatform.v1\x1a\x1cgoogle/api/annotations.proto\x1a\x17google/api/client.proto\x1a\x1fgoogle/api/field_behavior.proto\x1a\x19google/api/resource.proto\x1a\x33google/cloud/aiplatform/v1/prediction_service.proto\x1a\x1cgoogle/protobuf/struct.proto\"\x86\x01\n\x14\x43omputeTokensRequest\x12=\n\x08\x65ndpoint\x18\x01 \x01(\tB+\xe2\x41\x01\x02\xfa\x41$\n\"aiplatform.googleapis.com/Endpoint\x12/\n\tinstances\x18\x02 \x03(\x0b\x32\x16.google.protobuf.ValueB\x04\xe2\x41\x01\x02\"/\n\nTokensInfo\x12\x0e\n\x06tokens\x18\x01 \x03(\x0c\x12\x11\n\ttoken_ids\x18\x02 \x03(\x03\"T\n\x15\x43omputeTokensResponse\x12;\n\x0btokens_info\x18\x01 \x03(\x0b\x32&.google.cloud.aiplatform.v1.TokensInfo2\xac\x05\n\x11LlmUtilityService\x12\x9d\x02\n\x0b\x43ountTokens\x12..google.cloud.aiplatform.v1.CountTokensRequest\x1a/.google.cloud.aiplatform.v1.CountTokensResponse\"\xac\x01\xda\x41\x12\x65ndpoint,instances\x82\xd3\xe4\x93\x02\x90\x01\"=/v1/{endpoint=projects/*/locations/*/endpoints/*}:countTokens:\x01*ZL\"G/v1/{endpoint=projects/*/locations/*/publishers/*/models/*}:countTokens:\x01*\x12\xa7\x02\n\rComputeTokens\x12\x30.google.cloud.aiplatform.v1.ComputeTokensRequest\x1a\x31.google.cloud.aiplatform.v1.ComputeTokensResponse\"\xb0\x01\xda\x41\x12\x65ndpoint,instances\x82\xd3\xe4\x93\x02\x94\x01\"?/v1/{endpoint=projects/*/locations/*/endpoints/*}:computeTokens:\x01*ZN\"I/v1/{endpoint=projects/*/locations/*/publishers/*/models/*}:computeTokens:\x01*\x1aM\xca\x41\x19\x61iplatform.googleapis.com\xd2\x41.https://www.googleapis.com/auth/cloud-platformB\xd4\x01\n\x1e\x63om.google.cloud.aiplatform.v1B\x16LlmUtilityServiceProtoP\x01Z>cloud.google.com/go/aiplatform/apiv1/aiplatformpb;aiplatformpb\xaa\x02\x1aGoogle.Cloud.AIPlatform.V1\xca\x02\x1aGoogle\\Cloud\\AIPlatform\\V1\xea\x02\x1dGoogle::Cloud::AIPlatform::V1b\x06proto3"

pool = Google::Protobuf::DescriptorPool.generated_pool

begin
  pool.add_serialized_file(descriptor_data)
rescue TypeError
  # Compatibility code: will be removed in the next major version.
  require 'google/protobuf/descriptor_pb'
  parsed = Google::Protobuf::FileDescriptorProto.decode(descriptor_data)
  parsed.clear_dependency
  serialized = parsed.class.encode(parsed)
  file = pool.add_serialized_file(serialized)
  warn "Warning: Protobuf detected an import path issue while loading generated file #{__FILE__}"
  imports = [
    ["google.protobuf.Value", "google/protobuf/struct.proto"],
  ]
  imports.each do |type_name, expected_filename|
    import_file = pool.lookup(type_name).file_descriptor
    if import_file.name != expected_filename
      warn "- #{file.name} imports #{expected_filename}, but that import was loaded as #{import_file.name}"
    end
  end
  warn "Each proto file must use a consistent fully-qualified name."
  warn "This will become an error in the next major version."
end

module Google
  module Cloud
    module AIPlatform
      module V1
        ComputeTokensRequest = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("google.cloud.aiplatform.v1.ComputeTokensRequest").msgclass
        TokensInfo = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("google.cloud.aiplatform.v1.TokensInfo").msgclass
        ComputeTokensResponse = ::Google::Protobuf::DescriptorPool.generated_pool.lookup("google.cloud.aiplatform.v1.ComputeTokensResponse").msgclass
      end
    end
  end
end
